import streamlit as st
import os
from datetime import datetime
from pathlib import Path
import re

# OpenAI API
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None


class SimpleKnowledgeBase:
    """ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ï¼ˆTXTã®ã¿ï¼‰"""
    
    def __init__(self):
        self.documents = []
    
    def extract_text_from_txt(self, file_path):
        """TXTãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except UnicodeDecodeError:
            try:
                with open(file_path, 'r', encoding='shift-jis') as f:
                    return f.read()
            except Exception as e:
                return f"TXTèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}"
        except Exception as e:
            return f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def add_document(self, file_path, file_name):
        """æ–‡æ›¸ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ï¼ˆTXTã®ã¿ï¼‰"""
        ext = Path(file_path).suffix.lower()
        
        if ext != '.txt':
            return False, "ç¾åœ¨TXTãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™"
        
        text = self.extract_text_from_txt(file_path)
        
        # æ–‡æ›¸ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰² (ç´„500æ–‡å­—ã”ã¨)
        chunks = self._split_text(text, chunk_size=500)
        
        # ãƒ¡ãƒ¢ãƒªã«ä¿å­˜
        self.documents.append({
            "file_name": file_name,
            "chunks": chunks,
            "full_text": text,
            "timestamp": datetime.now().isoformat(),
            "text_preview": text[:200]
        })
        
        return True, f"æ–‡æ›¸ã‚’è¿½åŠ ã—ã¾ã—ãŸ: {len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"
    
    def _split_text(self, text, chunk_size=500):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
        chunks = []
        sentences = text.split('ã€‚')
        current_chunk = ""
        
        for sentence in sentences:
            if len(current_chunk) + len(sentence) < chunk_size:
                current_chunk += sentence + "ã€‚"
            else:
                if current_chunk:
                    chunks.append(current_chunk)
                current_chunk = sentence + "ã€‚"
        
        if current_chunk:
            chunks.append(current_chunk)
        
        return chunks
    
    def search(self, query, top_k=3):
        """ã‚¯ã‚¨ãƒªã«é–¢é€£ã™ã‚‹æ–‡æ›¸ã‚’æ¤œç´¢ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ï¼‰"""
        if not self.documents:
            return []
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
        keywords = re.findall(r'\w+', query.lower())
        
        results = []
        for doc in self.documents:
            for chunk in doc['chunks']:
                score = sum(1 for keyword in keywords if keyword in chunk.lower())
                if score > 0:
                    results.append({
                        'text': chunk,
                        'score': score,
                        'file_name': doc['file_name']
                    })
        
        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        results.sort(key=lambda x: x['score'], reverse=True)
        
        # ä¸Šä½Kä»¶ã‚’è¿”ã™
        top_results = results[:top_k]
        return [r['text'] for r in top_results] if top_results else []
    
    def get_document_list(self):
        """ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹æ–‡æ›¸ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        return [{
            'file_name': doc['file_name'],
            'chunks': len(doc['chunks']),
            'timestamp': doc['timestamp'],
            'text_preview': doc['text_preview']
        } for doc in self.documents]


class CompanyAIAssistant:
    """ç¤¾å†…æƒ…å ±ç‰¹åŒ–å‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"""
    
    def __init__(self, knowledge_base, api_key=None):
        self.knowledge_base = knowledge_base
        self.api_key = api_key
        
        if OpenAI and api_key:
            self.client = OpenAI(api_key=api_key)
        else:
            self.client = None
    
    def generate_answer(self, question, context_docs):
        """è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆ"""
        if not self.client:
            return "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        context = "\n\n".join([
            f"ã€å‚è€ƒè³‡æ–™{i+1}ã€‘\n{doc}"
            for i, doc in enumerate(context_docs)
        ])
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        system_prompt = """ã‚ãªãŸã¯ç¤¾å†…æƒ…å ±ã«ç‰¹åŒ–ã—ãŸAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
æä¾›ã•ã‚ŒãŸç¤¾å†…æ–‡æ›¸ã‚’å‚ç…§ã—ã¦ã€è³ªå•ã«æ­£ç¢ºã«ç­”ãˆã¦ãã ã•ã„ã€‚
æ–‡æ›¸ã«è¨˜è¼‰ã•ã‚Œã¦ã„ãªã„æƒ…å ±ã«ã¤ã„ã¦ã¯ã€ã€Œæä¾›ã•ã‚ŒãŸæƒ…å ±ã§ã¯ä¸æ˜ã§ã™ã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
        
        user_prompt = f"""ä»¥ä¸‹ã®ç¤¾å†…æ–‡æ›¸ã‚’å‚ç…§ã—ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

ã€ç¤¾å†…æ–‡æ›¸ã€‘
{context}

ã€è³ªå•ã€‘
{question}

ã€å›ç­”ã€‘"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
        except Exception as e:
            return f"å›ç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"


def load_sample_documents(knowledge_base):
    """sample_documentsãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰æ–‡æ›¸ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ï¼ˆTXTã®ã¿ï¼‰"""
    sample_dir = Path("./sample_documents")
    if not sample_dir.exists():
        return 0
    
    count = 0
    for file_path in sample_dir.glob("*.txt"):
        success, _ = knowledge_base.add_document(str(file_path), file_path.name)
        if success:
            count += 1
    
    return count


@st.cache_resource
def get_knowledge_base():
    """ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦å†åˆ©ç”¨"""
    kb = SimpleKnowledgeBase()
    load_sample_documents(kb)
    return kb


def main():
    st.set_page_config(
        page_title="ç¤¾å†…æƒ…å ±ç‰¹åŒ–å‹AIæ¤œç´¢",
        page_icon="ğŸ¢",
        layout="wide"
    )
    
    st.title("ğŸ¢ ç¤¾å†…æƒ…å ±ç‰¹åŒ–å‹AIæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  (ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ)")
    st.markdown("---")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'knowledge_base' not in st.session_state:
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨
        st.session_state.knowledge_base = get_knowledge_base()
        st.session_state.sample_loaded = True
    
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®šã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        # OpenAI APIã‚­ãƒ¼å…¥åŠ›
        api_key_input = st.text_input(
            "OpenAI APIã‚­ãƒ¼",
            type="password",
            help="GPT-4ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã®APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            value=st.session_state.get('api_key', '')
        )
        
        # Streamlit Cloudã®secretsã‹ã‚‰ã‚‚å–å¾—ã‚’è©¦ã¿ã‚‹
        if not api_key_input:
            try:
                api_key_input = st.secrets["openai"]["api_key"]
                st.success("âœ… APIã‚­ãƒ¼ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
            except:
                pass
        
        if api_key_input:
            st.session_state.api_key = api_key_input
        
        st.markdown("---")
        st.header("ğŸ“š æ–‡æ›¸ç®¡ç†")
        
        # ã‚µãƒ³ãƒ—ãƒ«æ–‡æ›¸èª­ã¿è¾¼ã¿çŠ¶æ…‹ã®è¡¨ç¤º
        if st.session_state.get('sample_loaded'):
            st.info("ğŸ“‚ ã‚µãƒ³ãƒ—ãƒ«æ–‡æ›¸ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        uploaded_files = st.file_uploader(
            "ç¤¾å†…æ–‡æ›¸ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (TXTã®ã¿)",
            type=['txt'],
            accept_multiple_files=True,
            help="ç¾åœ¨TXTãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™"
        )
        
        if uploaded_files:
            for uploaded_file in uploaded_files:
                if st.button(f"ğŸ“„ {uploaded_file.name} ã‚’è¿½åŠ ", key=uploaded_file.name):
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                    temp_path = f"./temp_{uploaded_file.name}"
                    with open(temp_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ 
                    success, message = st.session_state.knowledge_base.add_document(
                        temp_path,
                        uploaded_file.name
                    )
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    try:
                        os.remove(temp_path)
                    except:
                        pass
                    
                    if success:
                        st.success(message)
                    else:
                        st.error(message)
        
        st.markdown("---")
        
        # ç™»éŒ²æ–‡æ›¸ä¸€è¦§
        st.subheader("ğŸ“‹ ç™»éŒ²æ¸ˆã¿æ–‡æ›¸")
        docs = st.session_state.knowledge_base.get_document_list()
        
        if docs:
            for doc in docs:
                with st.expander(f"ğŸ“„ {doc['file_name']}"):
                    st.write(f"**ãƒãƒ£ãƒ³ã‚¯æ•°:** {doc['chunks']}")
                    st.write(f"**ç™»éŒ²æ—¥æ™‚:** {doc['timestamp']}")
                    st.write(f"**ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:**")
                    st.text(doc['text_preview'])
        else:
            st.info("ã¾ã æ–‡æ›¸ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢: ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
    st.header("ğŸ’¬ AIæ¤œç´¢ãƒãƒ£ãƒƒãƒˆ")
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
    chat_container = st.container()
    
    with chat_container:
        for message in st.session_state.chat_history:
            if message['role'] == 'user':
                st.markdown(f"**ğŸ‘¤ ã‚ãªãŸ:** {message['content']}")
            else:
                st.markdown(f"**ğŸ¤– AI:** {message['content']}")
                if 'sources' in message:
                    with st.expander("ğŸ“š å‚è€ƒã«ã—ãŸæ–‡æ›¸"):
                        for i, source in enumerate(message['sources']):
                            st.text(f"--- å‚è€ƒ{i+1} ---\n{source}\n")
            st.markdown("---")
    
    # è³ªå•å…¥åŠ›
    question = st.text_input(
        "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        placeholder="ä¾‹: çµŒè²»ç”³è«‹ã®æ‰‹é †ã‚’æ•™ãˆã¦ãã ã•ã„",
        key="question_input"
    )
    
    col1, col2 = st.columns([1, 5])
    with col1:
        search_button = st.button("ğŸ” æ¤œç´¢", type="primary", use_container_width=True)
    with col2:
        clear_button = st.button("ğŸ—‘ï¸ å±¥æ­´ã‚’ã‚¯ãƒªã‚¢", use_container_width=True)
    
    if clear_button:
        st.session_state.chat_history = []
        st.rerun()
    
    if search_button and question:
        if not st.session_state.get('api_key'):
            st.error("âš ï¸ OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        else:
            with st.spinner("æ¤œç´¢ä¸­..."):
                # é–¢é€£æ–‡æ›¸ã‚’æ¤œç´¢
                context_docs = st.session_state.knowledge_base.search(question, top_k=3)
                
                if context_docs:
                    # AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’åˆæœŸåŒ–
                    assistant = CompanyAIAssistant(
                        st.session_state.knowledge_base,
                        st.session_state.api_key
                    )
                    
                    # å›ç­”ã‚’ç”Ÿæˆ
                    answer = assistant.generate_answer(question, context_docs)
                    
                    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
                    st.session_state.chat_history.append({
                        'role': 'user',
                        'content': question
                    })
                    st.session_state.chat_history.append({
                        'role': 'assistant',
                        'content': answer,
                        'sources': context_docs
                    })
                    
                    st.rerun()
                else:
                    st.warning("é–¢é€£ã™ã‚‹ç¤¾å†…æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ–‡æ›¸ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("""
    ### ğŸ“– ä½¿ã„æ–¹
    1. **ã‚µã‚¤ãƒ‰ãƒãƒ¼**ã‹ã‚‰OpenAI APIã‚­ãƒ¼ã‚’è¨­å®š
    2. ç¤¾å†…æ–‡æ›¸ï¼ˆTXTãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è¿½åŠ 
    3. ãƒãƒ£ãƒƒãƒˆæ¬„ã§è³ªå•ã‚’å…¥åŠ›ã—ã¦æ¤œç´¢
    4. AIãŒç¤¾å†…æ–‡æ›¸ã‚’å‚ç…§ã—ã¦å›ç­”ã‚’ç”Ÿæˆ
    
    ### ğŸ’¡ ç‰¹å¾´
    - **è¶…ã‚·ãƒ³ãƒ—ãƒ«**: ä¾å­˜é–¢ä¿‚ã‚’æœ€å°åŒ–ï¼ˆStreamlit + OpenAIã®ã¿ï¼‰
    - **ç¢ºå®Ÿã«å‹•ä½œ**: TXTãƒ•ã‚¡ã‚¤ãƒ«å°‚ç”¨
    - **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢**: é«˜é€Ÿã§è»½é‡
    - **ã‚µãƒ³ãƒ—ãƒ«æ–‡æ›¸**: è‡ªå‹•çš„ã«`sample_documents`ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰èª­ã¿è¾¼ã¿
    
    ### âš ï¸ æ³¨æ„äº‹é …
    - OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ï¼ˆGPT-4ã‚’ä½¿ç”¨ï¼‰
    - ç¾åœ¨TXTãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾å¿œ
    - PDF/DOCXã‚’ä½¿ã„ãŸã„å ´åˆã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã¦ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„
    """)


if __name__ == "__main__":
    main()
